
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\setlength\parindent{0pt}


\usepackage{fullpage}
\usepackage[natbib=true,citestyle=authoryear,backend=bibtex,useprefix]{biblatex}
\addbibresource{library.bib}
%\usepackage{natbib}
\usepackage[dvips]{graphicx}
\usepackage{lipsum}
\usepackage[utf8]{inputenc} % Input encoding and font encoding
%\usepackage[margin = 1in]{geometry} % Margins
\usepackage{setspace} % Setting the spacing between lines
\usepackage{amsthm, amsmath, amsfonts, mathtools, amssymb} % Math packages
\usepackage{sgame, tikz} % Game theory packages
\usepackage{pgf}
\usetikzlibrary{trees, calc} % For extensive form games
\usepackage{pgfplots}
\usepackage{subfig} % Manipulation and reference of small or sub figures and tables
\usepackage{multirow,array}
%\usepackage[margin = 1in]{geometry} % Margins
\usetikzlibrary{calc}
\usetikzlibrary{matrix}
\usetikzlibrary{positioning}
\usepackage[mathscr]{euscript}
\usepackage{enumitem}
\usetikzlibrary{3d}
\usetikzlibrary{calc,fadings,decorations.pathreplacing}
\usepackage{bm,color}
\usepackage{makecell}
\usepackage{multicol}
\usepackage{float}
\restylefloat{table}
\usepackage{stackengine}
\usepackage{todonotes}
\newcommand*{\mtodo}[1]{\todo[color=violet!50]{Mikael: #1}}
\newcommand{\Mtodo}[1]{\todo[inline,color=violet!50]{Mikael: #1}}
\usepackage{comment}
\usepackage{caption}
\usepackage[capitalize]{cleveref}
\usepackage{times}
\usetikzlibrary{arrows}
\usepackage{algorithm}
\usepackage{algorithmic}
\graphicspath{{UsedPlots/}}

% Theorems

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}

\newtheorem{definition}[theorem]{Definition}
\newtheorem{examplex}[theorem]{Example}
\newenvironment{example}
  {\pushQED{\qed}\renewcommand{\qedsymbol}{$\diamondsuit$}\examplex}
  {\popQED\endexamplex}

\newtheorem{notation}[theorem]{Notation}  

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
  

% To cite Rapoport et al.
\newcommand{\citefirst}[1]{%
  \AtNextCite{\defcounter{maxnames}{1}\defcounter{minnames}{1}}%
  \citet{#1}%
}


\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\sign}{{\rm sign}}


\usepackage{accents}
\newcommand{\ubar}[1]{\underaccent{\bar}{#1}}




\title{The Early History of Game Theory}
\author{Mikael Böörs}
\affil{University of Gothenburg}
\date{December 2017}

\begin{document}

\maketitle
\thispagestyle{empty}
\newpage
\cleardoublepage
\setcounter{page}{1}

\section{Introduction}
What is game theory? The modern definition of \emph{game theory} is
the study of strategic interaction between rational agents. In this
context the word \emph{strategic} means that the actions of the agents
in a game has an impact on the outcome of the game for themselves and
for the other agents. It is also assumed that all agents, or \emph{players}, are aware of
this fact. The term \emph{rational} means that the agents chooses the
action that maximizes theirs expected utility, or in other words the
action that they expect will lead to the subjectively best possible
outcome based on the information available. The fact that the outcome
does not depend on any single agent separates the field of game theory
from the simpler field of decision theory which is the mathematical
study of the optimal decision-making for a single agent. 

\begin{itemize}
    \item Difference between game theory and decision theory
    \item Examples of fields 
\end{itemize}

\section{The History of Game Theory}\label{The History of Game Theory}

The field of game theory is quite young. In fact it was only established
as a mathematical field in in the beginning of the 20th century with
the work of John von Neumann (1903-1957). However, game
theoretical problems and questions regarding the optimal strategies in
situations where the outcomes depend on the choices of many have been
pondered throughout history by both philosophers, military
strategists, political leaders and the common man. A famous example of
a decision problem was stated by Blaise Pascal (1623-1662) and is
commonly refereed to as \emph{Pascal's Wager}. The thought experiment
was designed to motivate the rationality of believing in god and is
formulated as follows. There are two possibilities: \emph{God exists}
and \emph{God does not exist}. An individual has two choices:
\emph{Believe in god} and \emph{Not believe in god}. If one believes
in god and god exists the outcome will be endless happiness and if god
does not exist the loss will be finite. If one does not believe in god
and god exists the result will be eternal suffering, while the result
will be finite happiness if god does not exist. The problem can be
represented in a \emph{game matrix} as illustrated in Table~\ref{Pascal}.  


\begin{table}[h!]
  \centering
  \setlength{\extrarowheight}{2pt}
  \begin{tabular}{cc|c|c|}
    & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Nature}\\
    & \multicolumn{1}{c}{} & \multicolumn{1}{c}{God exists}  &
                                                              \multicolumn{1}{c}{$\neg$
                                                               God exists}
    \\\cline{3-4}
\multirow{2}*{Human}  & Believe in god & Endless happiness & Finite loss \\\cline{3-4}
    & $\neg$ Believe in god & Eternal suffering & Finite happiness \\\cline{3-4}
  \end{tabular}
  \caption{Pascal's Wager}
  \label{Pascal}
\end{table}

Pascal argued that the expected happiness from believing in god was
infinite while the expected outcome from not doing so was infinite
suffering. Pascal's Wager has been the subject of much criticism, both
from mathematicians and philosophers \textbf{Some of the critisism
  will be mentioned in Section X}. Strictly speaking, Pascal's Wager is not a
game theoretical problem since there is only one player and therefore it
belongs to the field of decision theory. However the problem is a good
example of an early attempt to analyse decision making. Another
historical example of a thought experiment that actually is a game
theoretical problem and which is still analyzed by game theorists to
this day, is the famous game of \emph{Stag Hunt}. Stag Hunt was
formulated by Jean-Jacques Rousseau (1712-1778) as a morality problem
of social cooperation and the problem was formulated as a story of two
hunters (in some versions there are several hunters but the addition
of more players does not add anything interesting in this case). The
two hunters sets out on a hunt and they can choose to hunt either stag
or hare. There are plenty of hares so the hunters are confident that
they can kill one on their own. However there are not as many stags
and they believe that in order to kill a stag they must
cooperate. Killing a stag will result in a lot of food while killing
a hare will result in a smaller amount of food. Circumstances forces
them to make the decision to hunt stag or hare without discussing with
each other. Should they trust each other and hunt stag, or should they
go for the safe alternative of hunting hare? Again, this game can be
represented in a game matrix as illustrated in Table~\ref{Stag hunt 1}.\\ 

\begin{table}[h!]
  \centering
  \setlength{\extrarowheight}{2pt}
  \begin{tabular}{cc|c|c|}
    & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Hunter 2}\\
    & \multicolumn{1}{c}{} & \multicolumn{1}{c}{Stag}  &
                                                              \multicolumn{1}{c}{Hare}
    \\\cline{3-4}
\multirow{2}*{Hunter 1}  & Stag & (A lot of food, A lot of food) &
                                                                   (A small amount
                                        of food,
                                                                   No food) \\\cline{3-4}
    & Hare & (No food, A small amount
                                        of food) & (A small amount
                                        of food, A small amount
                                        of food) \\\cline{3-4}
  \end{tabular}
  \caption{Stag Hunt}
  \label{Stag hunt 1}
\end{table}

In contrast to Pascal's Wager, there is no obvious choice of action in
this game, but \textbf{we will analyze it further in section X when we
  have introduced the necessary game theoretical tools}.\\

Both of the examples above are examples of game theoretical
problems. However the first known strict solution to a game theoretical
problem was provided by the armature matheamtician Francis Waldegrave
in 1713 \citep{Fillion2015}. Waldegrave provided a minimax solution to
the card game \emph{le Her}. The game is quite complex and I
will not describe it here. Instead I refer the interested reader to
the article by \cite{Fillion2015}. However a minimax strategy is a
\mtodo{This is wrong.}
strategy that minimizes the maximum loss in a game and maximizes the
minimum gain. This concept was studied in detail in 1928 by John von
Neumann who lay the foundation for the modern field of game theory.\\

In 1913 the German mathematician Ernst Zermelo (1971-1953) published
the first theorem that can be considered as a game theoretical
theorem. In the article \emph{Uber eine Anwendung der Mengenlehre auf die
  Theorie des Schachspiels} Zermelo provides a theorem that states
that in the game of chess, on of the three statements holds:
\begin{itemize}
\item White has a winning strategy
\item Black has a winning strategy
  \item Each of the two players has a strategy guaranteeing at least a
    draw. \citep{Schwalbe2001}
  \end{itemize}
  A winning strategy is a strategy that always wins, regardless of the
  opponents strategy and similarly a strategy that guarantees a draw
  guarantees a draw regardless of the opponents strategy. We do not
  know which of the statements that hold, but Zermelo tried to prove
  that one of the statements must hold using backward
  induction. However was only successful in part. The proof was
  completed by the joint efforts of Dénes König (1884-1944) and László
  Kalmár (1905-1976) in 1928 and it was Kalmár who provided the final proof
  (which was based on Zermelos original idea). Not only did Kalmár manage
  to prove that Zalermos statement holds, but he also generalized it to
  what is known as \emph{Zermelos thorem}. It states that in any
  sequential game of prefect information and in which no randomness is
  involved, either the first or the second player has a winning
  strategy or both players has a strategy guaranteeing at least a
    draw. \citep{Schwalbe2001} A sequential game is a game where the players takes turn to
    make a move and the term \emph{perfect information} refers to the
    fact that both players witness the all draws of the game.\\

    In 1928 John von Neumann published the article \emph{Zur
      Theorie der Gesellschaftsspiele} where he proved his famous
    \emph{Minimax theorem} that lay the foundation for the modern
    field of game theory. In order to understand the result presented
    in that article it is necessary to understand some basic game
    theoretical concepts. Therefore, before I present the remarkable
    work of von Neumann, I will introduce the necessary game theory in
    Section~\ref{Strategic Games}. 
  
\section{Strategic Games}\label{Strategic Games}
There are several types of games and different representations of
these games. In this section I will present a type of games called
simultaneous \emph{strategic games} or \emph{normal-form
  games}. \textbf{Mention that these types of games are the original
  types of games}. The word \emph{simultaneous} refers to the fact that all
players make their move without knowing the moves of the other
players. This can be thought of as a game where all players move at
the same time and the combination of their moves determines their
individual utility, or \emph{payoff}. In contrast, \emph{sequential
  games} are games where some players make a move after the other
players. These games are normally represented as \emph{extensive-form
  games} and they will not be covered in this section. \\

In order to be able to formally define a strategic game, I
will first introduce some definitions that are central for the
theory.

\begin{definition} (Set of Actions) \label{Set of actions}\\
  Let $P = \{P_1,...,P_n\}$ be a set of players. For $P_i
  \in P$ we define the \emph{set of actions} $A_i =
  \{a_{i1},...,a_{im}\}$ as the set of all possible actions available
  to player $P_i$. 
  \end{definition}

\begin{definition} (Pure Strategy) \label{Strategy}\\
  Let $P = \{P_1,...,P_n\}$ be a set of players in a game. For $P_i
  \in P$ we define a \emph{pure strategy} $s_i$ as a mapping between each
  game situation and an element in $A_i$. $S_i$ is the \emph{set of
    pure strategies} of player $i$.
\end{definition}

In Definition~\ref{Set of actions}, an action should be though of as a
legal move. Definition~\ref{Strategy} is more general than necessary
when only considering strategic games that are only played once. The
set of pure strategies of a player in such games could be considered
equivalent to the set of actions, However in iterative strategic games
the distinction between an action and a pure strategy is
important. If nothing else is mentioned, I will use the word
\emph{strategies} to refer to pure strategies.   

\begin{definition} (Strategy profile) \label{Strategy profile}\\
  Let $P = \{P_1,...,P_n\}$ be a set of players in a game. A
  \emph{strategy profile} $s = \{s_1,...,s_n\}$ is a combination of
  strategies of player $1,...,n$. $S = \prod_{i \in \{1,...,|P|\}}^n
  S_i $ is the set of all strategy profiles.
\end{definition}

In the game examples presented in Section~\ref{The History of Game
  Theory} the outcomes were states of the world such as \emph{A lot of
food} or \emph{A small amount of food}. This is fine if all you want
to do is to analyze a specific situation. However if you want to study
abstract situations this will not do and this motivated John von
Neumann and Oskar Morgenstern to develop their famous \emph{utility
  theory} in the book \emph{Theory of Games and Economic Behavior} in
1944. Because of page limitations I will not present the theory
in detail but rather give an intuitive description of it and hope that
it will suffice for the objective of this article. Their main idea was
that given a set of outcomes $O = \{o_1,...,o_n\}$ it is sometimes
possible to define a binary relation $\succsim$ over $O$ so that $o_i
\succsim o_j$ is true if and only if the outcome $o_i$ is preferred over the
outcome $o_j$ or if the outcomes are considered equally
preferable. The symbol $\succ$ means that the preference relationship
is strict. \citep{Maschler} This motivates Definition~\ref{Payoff}.

\begin{definition} (Payoff) \label{Payoff}\\
  Let $P = \{P_1,...,P_n\}$ a the set of players in a game. Let $S$ be
  a set of strategy profiles and $\succsim$ be a complete, reflexive
  and transitive preference relation over $S$. The
  \emph{utility function} of player $i$ is a function $u_i : S
  \rightarrow \mathbb{R}$ that maps a every strategy profile $s \in S$
  to a \emph{payoff} $p \in \mathbb{R}$ such that $s_k \succsim s_l
  \Leftrightarrow u_i(s_k) \geq u_i(s_l)$. $U = \{u_1,...,u_n\}$ is the
  set of utility functions of player $1,...,n$.
\end{definition}

Equipped with the definitions above, we are now ready to formally
define a strategic game.

\begin{definition} (Strategic Game) \label{Strategic Game}\\
  Let $P = \{P_1,...,P_n\}$ be a set of players with $n \geq 2$. Let
  $U$ be the set of utility functions of the players and let $S$
  be the set of all possible strategy profiles. Let $G$ be the triplet
  $(P,U,S)$. $G$ is an \emph{n-player strategic game}.  
\end{definition}

Strategic games with $n$ players with $|A_1| = m_1,...,|A_n| = m_n$
are often denoted as a $m_1 \times .... \times m_n$-game and in the
case where $n = 2$ the game is commonly represented as a $m_1 \times
m_2$ bi-matrix as illustrated in Table~\ref{bi-matrix}.\\

\begin{table}[h!]
  \begin{center}
    \setlength{\extrarowheight}{2pt}
    \begin{tabular}{cc|c|c|c|}
      & \multicolumn{2}{c}{} & \multicolumn{1}{c}{Player $2$} & \multicolumn{1}{c}{}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$a_{21}$}  &
                                                          \multicolumn{1}{c}{$a_{22}$} & \multicolumn{1}{c}{$a_{23}$} \\\cline{3-5}
      \multirow{2}*{Player $1$}  & $a_{11}$ & $(a,b)$ & $(c,d)$ & $(e,f)$\\\cline{3-5}
      & $a_{12}$ & $(g,h)$ & $(i,j)$ & $(k,l)$\\\cline{3-5}
    \end{tabular}
    \caption{An example of a $2 \times 3$ game represented as a $2
      \times 3$ bi-matrix. The elements corresponds to the payoffs for
      all strategy profiles. For example strategy profile
      $(a_{12},a_{22})$ results in payoff $u_1(a_{12},a_{22}) = i$ for
      player $1$ and payoff $u_2(a_{12},a_{22}) = j$ for player $2$.}
    \label{bi-matrix}
    \end{center}
  \end{table}

Let us return to the game \emph{Stag Hunt} again, but this time we can
use von Neumann-Morgenstern utility theory to generalize the game to
all situations with the same preference relationships. It seems
reasonable to assume that Rousseau had the following preference
relationships in mind: \emph{A lot of food} $\succ$ \emph{A small
  amount of food} $\succ$ \emph{No food}. This means that we can
represent the game as illustrated in Table~\ref{Stag Hunt 2}.Of course, there are other possible utility functions that would
satisfy Definition~\ref{Payoff} and therefore there are several
(infinite) many games of Stag Hunt. It is also always possible to
apply a positive linear transformation to the payoffs in a game
without changing the choices of strategies in the game. This is called
\emph{strategic equivalence}. \\

\begin{table}[h!]
  \centering
  \setlength{\extrarowheight}{2pt}
  \begin{tabular}{cc|c|c|}
    & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player 2}\\
    & \multicolumn{1}{c}{} & \multicolumn{1}{c}{0}  &
                                                              \multicolumn{1}{c}{1}
    \\\cline{3-4}
\multirow{2}*{Player 1}  & 0 & (1, 1) &
                                                                   (-1,0) \\\cline{3-4}
    & 1 & (0, -1) & (0,0) \\\cline{3-4}
  \end{tabular}
  \caption{Generalized version of Rousseaus Stag Hunt.}
  \label{Stag Hunt 2}
\end{table}

I will now introduce the concept of \emph{zero-sum games}. Zero-sum
games are arguably the simplest types of games and it was thees games
that von Morgenstern studied in the beginning of the 20th century. A
zero-sum game is a game $G$ such that the sum of the payoffs is zero
for every strategy profile, or $G = (P,U,S)$ is a zero-sum game if $\forall s
\in S~\sum_{i \in \{1,...,|P|\}} u_i(s) = 0$. An example pf a famous
zero-sum game is the game of \emph{Rock, Paper, Scissors}. The game
matrix is shown in Table~\ref{Rock Paper Scissors}.\\

\begin{table}[h!]
  \begin{center}
    \setlength{\extrarowheight}{2pt}
    \begin{tabular}{cc|c|c|c|}
      & \multicolumn{2}{c}{} & \multicolumn{1}{c}{Player $2$} & \multicolumn{1}{c}{}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{Rock}  &
                                                          \multicolumn{1}{c}{Paper} & \multicolumn{1}{c}{Scissors} \\\cline{3-5}
      \multirow{2}*{Player $1$}  & Rock & $(0,0)$ & $(-1,1)$ & $(1,-1)$\\\cline{3-5}
      & Paper & $(1,-1)$ & $(0,0)$ & $(-1,1)$\\\cline{3-5}
           \multirow{1}*{}  & Scissors & $(-1,1)$ & $(1,-1)$ & $(0,0)$\\\cline{3-5}   \end{tabular}
    \caption{An example of the $3\times 3$ zero-sum game \emph{Rock,
        Paper, Scissors}.}
    \label{Rock Paper Scissors}
    \end{center}
  \end{table}


So far we have
only considered representation of games, but what about solutions?
Is there a best strategy and if so what is it? It was these types of
questions that von Neumann thought about. Von Neumann, who only
considered two player zero-sum games, reasoned that if
a player is not guaranteed his highest payoff, the best thing he can
do is try to maximize his minimum payoff. If for example player $1$
chooses strategy $s_i \in S_1$, the worst payoff payoff the player can
receive is given by $$min_{s \in S_2} u_1(s_i,s).$$ Remember that in
zero-sum games, if player $2$ gets his maximum payoff, players $1$
will get his minimum payoff. This fact makes it relevant to consider
the minimizing expression above. A \emph{maxmin} strategy of player
$1$ is a strategy given by $$argmax_{s_1 \in S_1} min_{s_2 \in S_2}
u_1(s_1,s_2).$$ We define the \emph{maxmin value of player $1$} as
$\ubar{v}_1 = max_{s_1 \in S_1} min_{s_2 \in S_2}u_1(s_1,s_2)$ and
analogously we define the \emph{maxmin value of player $2$} as
$\ubar{v}_2 = max_{s_2 \in S_2} min_{s_1 \in
  S_1}u_2(s_1,s_2)$. However since $u_2 = -u_1$ in two player zero-sum
games we have that $\ubar{v}_2 = -min_{s_2 \in S_2} max_{s_1 \in S_1}
u_1(s_1,s_2)$. This motivates Definition~\ref{optimal strategy}.

\begin{definition} (Optimal strategy)\label{optimal strategy}\\

  Let $G = (P,U,S)$ be a two players zero-sum game and
  let 
\begin{equation}
\begin{gathered}
\ubar{v} = max_{s_1 \in S_1} min_{s_2 \in S_2}u_1(s_1,s_2) \\
\bar{v} = min_{s_2 \in S_2} max_{s_1 \in S_1}u_1(s_1,s_2)
\end{gathered}
\end{equation} and
   be the \emph{maxmin value} and the \emph{minmax value}
of $G$. If $\ubar{v} = \bar{v} \triangleq V$ then $V$ is called the
\emph{value} of $G$ and any strategies $s_1^* \in S_1$ and $s_2^* \in S_2$
such that 
\begin{equation}
\begin{gathered}
s_1^* = argmax_{s_1 \in S_1} min_{s_2 \in S_2}u_1(s_1,s_2) \\
s_2^* = argmin_{s_2 \in S_2} max_{s_1 \in S_1}u_1(s_1,s_2)
\end{gathered}
\end{equation}
are called \emph{optimal strategies} for player $1$ and
$2$ respectively. \citep{Maschler}
\end{definition}

$\ubar{v}$ should be interpreted as the payoff that player $1$ can
guarantee for himself and player $2$ is can guarantee himself that he
never will have to pay more than $\bar{v}$. If a game has a value and
$\ubar{v} = \bar{v}$ then the game has an equilibrium since neither
player would want to defect from an optimal strategy profile. Does
every two player zero-sum game have optimal strategies? The answer is
no. Consider for example the game of rock, paper, scissors in
Table~\ref{Rock Paper Scissors}. The maxmin value $\ubar{v} = -1$ but
the minmax value $\bar{v} = 1$. Since $\ubar{v} \neq \bar{v}$ the game
has no optimal pure strategies. In contrast, the game presented in
Table~\ref{value game} does have a value and hence it also has optimal
(pure) strategies. The value is $V = 1$ and the optimal strategies are
$2$ for player $1$ and $3$ for player $2$. This means that player $1$
can get at least $1$ in payoff and player $2$ can make sure that he
will not have to pay more than $1$ in payoff. Therefore the game is in
an equilibrium in the strategy profile $(2,3)$.

\begin{table}[h!]
  \begin{center}
    \setlength{\extrarowheight}{2pt}
    \begin{tabular}{cc|c|c|c|}
      & \multicolumn{2}{c}{} & \multicolumn{1}{c}{Player $2$} & \multicolumn{1}{c}{}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{1}  &
                                                          \multicolumn{1}{c}{2} & \multicolumn{1}{c}{3} \\\cline{3-5}
      \multirow{2}*{Player $1$}  & 1 & $(3,-3)$ & $(-5,5)$ & $(-2,2)$\\\cline{3-5}
      & 2 & $(1,-1)$ & $(4,-4)$ & $(1,-1)$\\\cline{3-5}
           \multirow{1}*{}  & 3 & $(6,-6)$ & $(-3,3)$ & $(-5,5)$\\\cline{3-5}   \end{tabular}
    \caption{An example of the $3\times 3$ zero-sum game with a pure
      strategy solution in (2,3).}
    \label{value game}
    \end{center}
  \end{table}

We have now established that some two player zero-sum games does have
optimal strategies and that some does not. Does this mean that we
cannot solve these games? Not at all. Von Neumann did not stop here
but rather turned his attention to other types of strategies. So far
we have only considered deterministic strategies, i.e.\ strategies
that will always choose the same actions in equivalent situations. But
von Neumann was interested in stochastic strategies, or \emph{mixed
  strategies}.

\begin{definition}(Mixed strategy)\label{mixed strategy}\\
  Let $G = (P,U,S)$ be a finite strategic game, i.e.\ a game with $|S|
  < \infty $. For $i \in \{1,...,|P|\}$ we define $\Sigma_i$ as the set
  of all possible probability distributions over $S_i$. Let
  $\Sigma = \prod_{i \in \{1,...,|P| \}} \Sigma_i$. We call an element
    $\sigma_i \in \Sigma_i$ a \emph{mixed strategy} and
  an element $\sigma \in \Sigma$ is called a \emph{mixed strategy
    profile}. \citep{Gonzalez-Diaz2010}
  \end{definition}


  \begin{definition}(Mixed extension)\label{Mixed extension}\\
Given a finite game $G = (S,U,P)$ we define the \emph{mixed
  extension} of $G$, denoted $\Gamma(G)$, as the strategic game
$\Gamma(G) = (\Sigma,\mu,P)$. $\mu$ is the set
of pay-off functions $\mu_i$ for every player $i$, where $\mu _i(\sigma) \triangleq \mathbb{E}[u_i(\sigma
  )] =\sum_{s\in S} u_i(s)\sigma_1(s_1) \cdot...\cdot \sigma_n(s_n)$ $\forall
\sigma \in \Sigma$. \citep{Gonzalez-Diaz2010}\\ 
\end{definition}

In the mixed extension of a strategic game $G$ we allow for stochastic
strategies and therefore the payoffs are calculated as
expectations. This approach is very reasonable in many
situations. Consider for example once again the game of rock, paper, scissors. It does not seem like a good approach to use a deterministic
strategy. But does there exist optimal strategies in the mixed
extension of a two player zero sum game? The answer was given in 1928
when John von Neumann published his article \emph{Zur Theorie der
  Gesellschaftsspiele} with his famous \emph{minimax theorem}.

\begin{theorem}(minimax)\\
Let $G = (P,U,S)$ be a strategic zero-sum game with $|P| = 2$ and $|S|
< \infty$ and let $\Gamma (G)$ be the mixed extension of $G$. Then
$\Gamma (G)$ has a value $V$ such that
\begin{equation}
  V = max{\sigma _1 \in
  \Sigma_1} min_{\sigma _2 \in \Sigma_2} \mu_1(\sigma_1,\sigma_2) = min_{\sigma _2 \in
  \Sigma_2} max_{\sigma _1 \in \Sigma_1} \mu_1(\sigma_1,\sigma_2)
\end{equation}
and all mixed strategies $\sigma _1^* \in \Sigma_1$ and $\sigma _2^*
\in \Sigma_2$ such that
\begin{equation}
  \begin{gathered}
\sigma_1^* = argmax_{\sigma _1 \in
  \Sigma_1} min_{\sigma _2 \in \Sigma_2} \mu_1(\sigma_1,\sigma_2)\\
 \sigma_2^* = argmin_{\sigma _2 \in \Sigma_2} max_{\sigma _1 \in
   \Sigma_1} \mu_1(\sigma_1,\sigma_2)
\end{gathered}
\end{equation}
 are optimal mixed strategies for player $1$ and $2$ respectively.
\end{theorem}

The publication of the minimax theorem are often considered to be the
birth of the mathematical field of game theory. However the true
breakthrough for game theory did not come until 1944 when John von
Neumann and Oskar Morgenstern published their book \emph{Theory of
  Games and Economic Behavior} which contained the minimax theorem
with a different proof, their utility theory
(which was briefly discussed earlier) and a formalization
of many game theoretical concepts. It was this book that triggered the
game theoretical hype that started a few years after its
publication.
\section{The Standard Games}

\section{Other Types of Games}

\newpage

\printbibliography


\end{document}